{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"bhut","text":"<p>bhut is a fast, flexible Barnes-Hut algorithm implementation for N-body force calculations in Python. It provides O(N log N) tree construction and O(M log N) force evaluation, making it ideal for large-scale simulations in astrophysics, molecular dynamics, and other domains requiring efficient long-range force computations.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Fast: Optimized tree construction and traversal algorithms</li> <li>Flexible: Multiple backends (NumPy, Dask) for different scales</li> <li>Accurate: Configurable approximation parameters</li> <li>Pythonic: Clean API supporting both functional and object-oriented usage</li> </ul>"},{"location":"#quick-install","title":"Quick Install","text":"<pre><code>pip install bhut\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>import bhut\nimport numpy as np\n\n# Generate some particles\npositions = np.random.rand(1000, 2)\nmasses = np.ones(1000)\n\n# Compute forces\nforces = bhut.force(positions, masses, theta=0.5)\n</code></pre>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<ul> <li>Getting Started - Installation and first examples</li> <li>Usage Guide - Parameters, 2D/3D usage, advanced features</li> <li>API Reference - Complete function and class documentation</li> <li>Theory - Mathematical background and algorithms</li> <li>Development - Contributing and development setup</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":"<p>Install bhut from PyPI using pip:</p> <pre><code>pip install bhut\n</code></pre> <p>For development or the latest features:</p> <pre><code>pip install git+https://github.com/username/bhut.git\n</code></pre>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/#functional-interface","title":"Functional Interface","text":"<p>The simplest way to use bhut is through the functional interface:</p> <pre><code>import bhut\nimport numpy as np\n\n# Create sample data\nn_particles = 1000\npositions = np.random.rand(n_particles, 2)  # 2D positions\nmasses = np.ones(n_particles)\n\n# Compute forces using Barnes-Hut algorithm\nforces = bhut.force(positions, masses, theta=0.5)\n\n# Compute potential energy\npotential = bhut.potential(positions, masses, theta=0.5)\n</code></pre>"},{"location":"getting-started/#object-oriented-interface","title":"Object-Oriented Interface","text":"<p>For more control and repeated calculations:</p> <pre><code>import bhut\nimport numpy as np\n\n# Create and configure the tree\ntree = bhut.Tree(\n    positions=positions,\n    masses=masses,\n    theta=0.5,\n    leaf_size=10\n)\n\n# Compute forces on the same particles\nforces = tree.force()\n\n# Or compute forces on different target positions\ntarget_positions = np.random.rand(500, 2)\nforces_on_targets = tree.force(target_positions)\n\n# Access tree properties\nprint(f\"Tree depth: {tree.depth}\")\nprint(f\"Number of nodes: {tree.n_nodes}\")\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about parameters and configuration</li> <li>Explore the complete API reference</li> <li>Understand the theory behind Barnes-Hut</li> </ul>"},{"location":"usage/","title":"Usage Guide","text":""},{"location":"usage/#key-parameters","title":"Key Parameters","text":""},{"location":"usage/#theta","title":"theta (\u03b8)","text":"<p>The theta parameter controls the accuracy-speed tradeoff:</p> <ul> <li><code>theta = 0.0</code>: Exact calculation (equivalent to brute force)</li> <li><code>theta = 0.5</code>: Good balance of speed and accuracy (recommended default)</li> <li><code>theta = 1.0</code>: Faster but less accurate</li> <li><code>theta &gt; 1.0</code>: Very fast but potentially poor accuracy</li> </ul> <pre><code># High accuracy, slower\nforces = bhut.force(positions, masses, theta=0.1)\n\n# Balanced (recommended)\nforces = bhut.force(positions, masses, theta=0.5)\n\n# Fast approximation\nforces = bhut.force(positions, masses, theta=1.0)\n</code></pre>"},{"location":"usage/#leaf_size","title":"leaf_size","text":"<p>Controls when to stop subdividing tree nodes:</p> <pre><code># Smaller leaves = deeper tree, more accurate but slower\ntree = bhut.Tree(positions, masses, leaf_size=5)\n\n# Larger leaves = shallower tree, faster but less accurate\ntree = bhut.Tree(positions, masses, leaf_size=20)\n</code></pre>"},{"location":"usage/#softening","title":"softening","text":"<p>Softening parameter to avoid singularities at short distances:</p> <pre><code># Add softening for numerical stability\nforces = bhut.force(positions, masses, softening=0.01)\n</code></pre>"},{"location":"usage/#2d-vs-3d-usage","title":"2D vs 3D Usage","text":""},{"location":"usage/#2d-problems","title":"2D Problems","text":"<pre><code># 2D positions (N x 2 array)\npositions_2d = np.random.rand(1000, 2)\nforces_2d = bhut.force(positions_2d, masses, theta=0.5)\n</code></pre>"},{"location":"usage/#3d-problems","title":"3D Problems","text":"<pre><code># 3D positions (N x 3 array)\npositions_3d = np.random.rand(1000, 3)\nforces_3d = bhut.force(positions_3d, masses, theta=0.5)\n</code></pre>"},{"location":"usage/#source-vs-target-particles","title":"Source vs Target Particles","text":"<p>You can compute forces on different target positions than source positions:</p> <pre><code># Source particles (create the tree)\nsource_pos = np.random.rand(10000, 2)\nsource_masses = np.ones(10000)\n\n# Target particles (where we want forces)\ntarget_pos = np.random.rand(100, 2)\n\n# Compute forces on targets due to sources\ntree = bhut.Tree(source_pos, source_masses)\nforces = tree.force(target_pos)\n</code></pre>"},{"location":"usage/#backends","title":"Backends","text":"<p>Choose different computational backends:</p> <pre><code># NumPy backend (default)\nforces = bhut.force(positions, masses, backend='numpy')\n\n# Dask backend for larger datasets\nforces = bhut.force(positions, masses, backend='dask')\n</code></pre>"},{"location":"usage/#advanced-examples","title":"Advanced Examples","text":""},{"location":"usage/#time-evolution","title":"Time Evolution","text":"<pre><code>import bhut\nimport numpy as np\n\n# Initial conditions\npositions = np.random.rand(1000, 2)\nvelocities = np.zeros_like(positions)\nmasses = np.ones(1000)\ndt = 0.01\n\n# Time stepping loop\nfor step in range(100):\n    # Compute forces\n    forces = bhut.force(positions, masses, theta=0.5)\n\n    # Update velocities and positions (leapfrog)\n    velocities += forces / masses[:, np.newaxis] * dt\n    positions += velocities * dt\n</code></pre>"},{"location":"usage/#custom-force-laws","title":"Custom Force Laws","text":"<pre><code># Different force kernels\nforces = bhut.force(positions, masses, kernel='gravitational')\nforces = bhut.force(positions, masses, kernel='coulomb')\n</code></pre>"},{"location":"api/","title":"API Reference","text":"<p>bhut: Barnes-Hut N-body accelerator that is array-agnostic.</p> <p>This package provides efficient N-body force calculations using the Barnes-Hut algorithm, with support for both NumPy and Dask arrays.</p>"},{"location":"api/#bhut.Tree","title":"Tree","text":"<p>Barnes-Hut tree for efficient N-body force calculations.</p> <p>This class provides an object-oriented interface to the Barnes-Hut algorithm, allowing for tree construction, refitting, and force evaluation.</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>array_like</code> <p>Initial particle positions, shape (N, dim)</p> required <code>masses</code> <code>array_like</code> <p>Initial particle masses, shape (N,)</p> required <code>leaf_size</code> <code>int</code> <p>Maximum particles per leaf node. Default: 32</p> <code>32</code> <code>backend</code> <code>str</code> <p>Array backend (\"numpy\", \"dask\", or \"auto\"). Default: \"auto\"</p> <code>'auto'</code> <code>dim</code> <code>int</code> <p>Spatial dimensions (2 or 3). Default: 3</p> <code>3</code> <p>Attributes:</p> Name Type Description <code>positions</code> <code>ndarray</code> <p>Particle positions, shape (N, dim)</p> <code>masses</code> <code>ndarray</code> <p>Particle masses, shape (N,)</p> <code>dim</code> <code>int</code> <p>Spatial dimensions</p> <code>leaf_size</code> <code>int</code> <p>Maximum particles per leaf node</p> <code>backend</code> <code>str</code> <p>Array backend being used</p> <code>_tree</code> <code>TreeData | None</code> <p>Internal tree data structure (None until built)</p> <code>_is_built</code> <code>bool</code> <p>Whether tree has been built</p> Source code in <code>bhut/api.py</code> <pre><code>class Tree:\n    \"\"\"\n    Barnes-Hut tree for efficient N-body force calculations.\n\n    This class provides an object-oriented interface to the Barnes-Hut algorithm,\n    allowing for tree construction, refitting, and force evaluation.\n\n    Parameters\n    ----------\n    positions : array_like\n        Initial particle positions, shape (N, dim)\n    masses : array_like\n        Initial particle masses, shape (N,)\n    leaf_size : int, optional\n        Maximum particles per leaf node. Default: 32\n    backend : str, optional\n        Array backend (\"numpy\", \"dask\", or \"auto\"). Default: \"auto\"\n    dim : int, optional\n        Spatial dimensions (2 or 3). Default: 3\n\n    Attributes\n    ----------\n    positions : ndarray\n        Particle positions, shape (N, dim)\n    masses : ndarray  \n        Particle masses, shape (N,)\n    dim : int\n        Spatial dimensions\n    leaf_size : int\n        Maximum particles per leaf node\n    backend : str\n        Array backend being used\n    _tree : TreeData | None\n        Internal tree data structure (None until built)\n    _is_built : bool\n        Whether tree has been built\n    \"\"\"\n\n    def __init__(\n        self,\n        positions: ArrayLike,\n        masses: ArrayLike,\n        *,\n        leaf_size: int = 32,\n        backend: str = \"auto\",\n        dim: int = 3,\n    ) -&gt; None:\n        # Validate and store parameters\n        _validate_dimensions(dim)\n\n        # Convert and validate inputs\n        self.positions, self.masses, _ = _validate_accelerations_inputs(\n            positions, masses,\n            dim=dim, softening=0.0, theta=0.5, G=1.0, leaf_size=leaf_size\n        )\n\n        self.dim = dim\n        self.leaf_size = leaf_size\n        self.backend = backend\n        self._tree: TreeData | None = None\n        self._is_built = False\n\n        # Get namespace for this backend\n        self._xp = get_namespace(self.positions, backend)\n\n    def build(self) -&gt; \"Tree\":\n        \"\"\"\n        Build the Barnes-Hut tree structure.\n\n        Returns\n        -------\n        self : Tree\n            Returns self for method chaining\n        \"\"\"\n        self._tree = build_tree(\n            self.positions, self.masses, \n            leaf_size=self.leaf_size, backend=self.backend, dim=self.dim\n        )\n        self._is_built = True\n        return self\n\n    def refit(self, new_positions: ArrayLike, new_masses: Optional[ArrayLike] = None) -&gt; \"Tree\":\n        \"\"\"\n        Refit the tree with new positions, keeping the same topology.\n\n        This is faster than rebuilding when particles move slightly.\n        Uses efficient O(M) algorithm where M is number of tree nodes.\n\n        Parameters\n        ----------\n        new_positions : array_like\n            New particle positions, shape (N, dim)\n        new_masses : array_like, optional\n            New particle masses, shape (N,). If None, keeps existing masses.\n\n        Returns\n        -------\n        self : Tree\n            Returns self for method chaining\n\n        Raises\n        ------\n        ValueError\n            If arrays have incompatible shapes or tree is not built\n        \"\"\"\n        if not self._is_built or self._tree is None:\n            raise ValueError(\"Tree must be built before refitting. Call build() first.\")\n\n        # Use existing masses if not provided\n        if new_masses is None:\n            new_masses = self.masses\n\n        # Validate inputs\n        new_positions, new_masses, _ = _validate_accelerations_inputs(\n            new_positions, new_masses,\n            dim=self.dim, softening=0.0, theta=0.5, G=1.0, leaf_size=self.leaf_size\n        )\n\n        # Check if refit is recommended vs rebuild\n        if not should_refit_vs_rebuild(self._tree, new_positions):\n            # Fall back to rebuild for major changes\n            return self.rebuild(new_positions, new_masses)\n\n        # Perform efficient refit\n        self._tree = refit_tree(self._tree, new_positions, new_masses, self._xp)\n\n        # Update stored arrays\n        self.positions = new_positions\n        self.masses = new_masses\n\n        return self\n\n    def rebuild(\n        self, new_positions: ArrayLike, new_masses: Optional[ArrayLike] = None\n    ) -&gt; \"Tree\":\n        \"\"\"\n        Rebuild the tree with new positions and optionally new masses.\n\n        Parameters\n        ----------\n        new_positions : array_like\n            New particle positions, shape (N, dim)\n        new_masses : array_like, optional\n            New particle masses, shape (N,). If None, keeps existing masses.\n\n        Returns\n        -------\n        self : Tree\n            Returns self for method chaining\n\n        Raises\n        ------\n        ValueError\n            If new arrays have incompatible shapes\n        \"\"\"\n        # Use existing masses if not provided\n        if new_masses is None:\n            new_masses = self.masses\n\n        # Validate new inputs\n        new_positions, new_masses, _ = _validate_accelerations_inputs(\n            new_positions, new_masses,\n            dim=self.dim, softening=0.0, theta=0.5, G=1.0, leaf_size=self.leaf_size\n        )\n\n        # Update stored arrays\n        self.positions = new_positions\n        self.masses = new_masses\n\n        # Mark as needing rebuild\n        self._is_built = False\n        self._tree = None\n\n        # Rebuild tree\n        return self.build()\n\n    def accelerations(\n        self,\n        targets: Optional[ArrayLike] = None,\n        *,\n        theta: float = 0.5,\n        softening: Union[float, ArrayLike] = 0.0,\n        G: float = 1.0,\n    ) -&gt; NDArray[np.floating[Any]]:\n        \"\"\"\n        Compute gravitational accelerations for target positions.\n\n        Parameters\n        ----------\n        targets : array_like, optional\n            Target positions, shape (M, dim). If None, evaluates accelerations\n            for the particles used to build the tree (self-evaluation).\n        theta : float, optional\n            Opening angle criterion. Default: 0.5\n        softening : float or array_like, optional\n            Plummer softening length. Default: 0.0\n        G : float, optional\n            Gravitational constant. Default: 1.0\n\n        Returns\n        -------\n        accelerations : ndarray\n            Gravitational accelerations, shape (M, dim)\n\n        Raises\n        ------\n        ValueError\n            If tree is not built or targets have wrong shape\n        \"\"\"\n        if not self._is_built:\n            raise ValueError(\"Tree must be built before evaluating accelerations\")\n\n        # Handle self-evaluation case\n        if targets is None:\n            return self.evaluate_accelerations(softening, theta, G)\n\n        # Check if targets is a Dask array and handle accordingly\n        if _is_dask_array(targets):\n            # Use Dask implementation for targets\n            return self._accelerations_dask_targets(\n                targets, theta=theta, softening=softening, G=G\n            )\n\n        # NumPy path - validate targets\n        targets = np.asarray(targets, dtype=np.float64)\n        if len(targets.shape) != 2:\n            raise ValueError(f\"targets must be 2D array, got shape {targets.shape}\")\n        if targets.shape[1] != self.dim:\n            raise ValueError(\n                f\"targets has {targets.shape[1]} dimensions but tree has {self.dim}\"\n            )\n\n        # Validate softening for target array size\n        if not np.isscalar(softening):\n            softening = np.asarray(softening, dtype=np.float64)\n            M = targets.shape[0]\n            if softening.shape != (M,):\n                raise ValueError(\n                    f\"softening array shape {softening.shape} does not match \"\n                    f\"targets shape ({M},)\"\n                )\n\n        # Validate other parameters\n        if theta &lt; 0:\n            raise ValueError(f\"theta must be non-negative, got {theta}\")\n\n        # Evaluate accelerations using tree  \n        # For targets, we need to compute the acceleration at each target point\n        # Use the specialized function for external targets\n        from .traverse.bh import barnes_hut_accelerations_targets\n\n        # Compute accelerations at target positions\n        acc = barnes_hut_accelerations_targets(\n            self._tree, self.positions, self.masses, targets, softening, theta, G\n        )\n\n        return acc\n\n    def _accelerations_dask_targets(\n        self,\n        targets: ArrayLike,\n        *,\n        theta: float = 0.5,\n        softening: Union[float, ArrayLike] = 0.0,\n        G: float = 1.0,\n    ) -&gt; ArrayLike:\n        \"\"\"Compute accelerations for Dask target arrays.\"\"\"\n        # Import Dask array operations\n        try:\n            import dask.array as da\n        except ImportError as e:\n            raise RuntimeError(\"Dask not available\") from e\n\n        # Get the Dask namespace\n        from .backends.dask_ import get_dask_namespace\n        xp = get_dask_namespace()\n\n        # Define chunk function for map_blocks\n        def _compute_targets_chunk_accelerations(targets_chunk, *, tree_data, source_pos, source_masses, \n                                               theta_val, softening_val, G_val):\n            \"\"\"Compute accelerations for a chunk of target positions.\"\"\"\n            from .traverse.bh import barnes_hut_accelerations_targets\n\n            # Compute accelerations for this chunk\n            return barnes_hut_accelerations_targets(\n                tree_data, source_pos, source_masses, targets_chunk, \n                softening_val, theta_val, G_val\n            )\n\n        # Use map_blocks to compute accelerations preserving chunking\n        return xp.map_blocks_accelerations(\n            _compute_targets_chunk_accelerations,\n            targets,  # targets (Dask array)\n            self._tree,       # tree data\n            self.positions,  # source positions (NumPy)\n            self.masses,     # source masses (NumPy)\n            theta_val=theta,\n            softening_val=softening,\n            G_val=G\n        )\n\n    def evaluate_accelerations(\n        self, \n        softening: Union[float, NDArray[np.floating[Any]]], \n        theta: float = 0.5,\n        G: float = 1.0\n    ) -&gt; NDArray[np.floating[Any]]:\n        \"\"\"\n        Evaluate gravitational accelerations for all particles in the tree.\n\n        Parameters\n        ----------\n        softening : float or array_like\n            Gravitational softening length(s). If scalar, same softening is used\n            for all particles. If array, must have shape (N,) for per-particle\n            softening.\n        theta : float, default 0.5\n            Opening angle criterion for Barnes-Hut approximation. Smaller values\n            give higher accuracy but slower computation. Typical range: 0.1-1.0.\n        G : float, default 1.0\n            Gravitational constant\n\n        Returns\n        -------\n        accelerations : array_like, shape (N, D)\n            Gravitational accelerations for each particle\n\n        Raises\n        ------\n        RuntimeError\n            If tree has not been built (call `build()` first)\n        ValueError\n            If input parameters have invalid shapes or values\n        \"\"\"\n        if self._tree is None:\n            raise RuntimeError(\"Tree not built. Call build() first.\")\n\n        # Validate inputs\n        if not isinstance(softening, (int, float)):\n            raise ValueError(\"Only scalar softening is currently supported\")\n\n        if softening &lt; 0:\n            raise ValueError(\"Softening must be non-negative\")\n\n        if theta &lt; 0:\n            raise ValueError(\"Opening angle theta must be non-negative\")\n\n        # Use the standalone function to compute accelerations\n        accelerations_np = evaluate_accelerations(\n            self._tree, self.positions, self.masses, theta, softening, G\n        )\n\n        # Convert back to original array type  \n        xp = get_namespace(self.positions, self.backend)\n        return xp.asarray(accelerations_np)\n</code></pre>"},{"location":"api/#bhut.Tree.accelerations","title":"accelerations","text":"<pre><code>accelerations(targets=None, *, theta=0.5, softening=0.0, G=1.0)\n</code></pre> <p>Compute gravitational accelerations for target positions.</p> <p>Parameters:</p> Name Type Description Default <code>targets</code> <code>array_like</code> <p>Target positions, shape (M, dim). If None, evaluates accelerations for the particles used to build the tree (self-evaluation).</p> <code>None</code> <code>theta</code> <code>float</code> <p>Opening angle criterion. Default: 0.5</p> <code>0.5</code> <code>softening</code> <code>float or array_like</code> <p>Plummer softening length. Default: 0.0</p> <code>0.0</code> <code>G</code> <code>float</code> <p>Gravitational constant. Default: 1.0</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>accelerations</code> <code>ndarray</code> <p>Gravitational accelerations, shape (M, dim)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If tree is not built or targets have wrong shape</p> Source code in <code>bhut/api.py</code> <pre><code>def accelerations(\n    self,\n    targets: Optional[ArrayLike] = None,\n    *,\n    theta: float = 0.5,\n    softening: Union[float, ArrayLike] = 0.0,\n    G: float = 1.0,\n) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"\n    Compute gravitational accelerations for target positions.\n\n    Parameters\n    ----------\n    targets : array_like, optional\n        Target positions, shape (M, dim). If None, evaluates accelerations\n        for the particles used to build the tree (self-evaluation).\n    theta : float, optional\n        Opening angle criterion. Default: 0.5\n    softening : float or array_like, optional\n        Plummer softening length. Default: 0.0\n    G : float, optional\n        Gravitational constant. Default: 1.0\n\n    Returns\n    -------\n    accelerations : ndarray\n        Gravitational accelerations, shape (M, dim)\n\n    Raises\n    ------\n    ValueError\n        If tree is not built or targets have wrong shape\n    \"\"\"\n    if not self._is_built:\n        raise ValueError(\"Tree must be built before evaluating accelerations\")\n\n    # Handle self-evaluation case\n    if targets is None:\n        return self.evaluate_accelerations(softening, theta, G)\n\n    # Check if targets is a Dask array and handle accordingly\n    if _is_dask_array(targets):\n        # Use Dask implementation for targets\n        return self._accelerations_dask_targets(\n            targets, theta=theta, softening=softening, G=G\n        )\n\n    # NumPy path - validate targets\n    targets = np.asarray(targets, dtype=np.float64)\n    if len(targets.shape) != 2:\n        raise ValueError(f\"targets must be 2D array, got shape {targets.shape}\")\n    if targets.shape[1] != self.dim:\n        raise ValueError(\n            f\"targets has {targets.shape[1]} dimensions but tree has {self.dim}\"\n        )\n\n    # Validate softening for target array size\n    if not np.isscalar(softening):\n        softening = np.asarray(softening, dtype=np.float64)\n        M = targets.shape[0]\n        if softening.shape != (M,):\n            raise ValueError(\n                f\"softening array shape {softening.shape} does not match \"\n                f\"targets shape ({M},)\"\n            )\n\n    # Validate other parameters\n    if theta &lt; 0:\n        raise ValueError(f\"theta must be non-negative, got {theta}\")\n\n    # Evaluate accelerations using tree  \n    # For targets, we need to compute the acceleration at each target point\n    # Use the specialized function for external targets\n    from .traverse.bh import barnes_hut_accelerations_targets\n\n    # Compute accelerations at target positions\n    acc = barnes_hut_accelerations_targets(\n        self._tree, self.positions, self.masses, targets, softening, theta, G\n    )\n\n    return acc\n</code></pre>"},{"location":"api/#bhut.Tree.build","title":"build","text":"<pre><code>build()\n</code></pre> <p>Build the Barnes-Hut tree structure.</p> <p>Returns:</p> Name Type Description <code>self</code> <code>Tree</code> <p>Returns self for method chaining</p> Source code in <code>bhut/api.py</code> <pre><code>def build(self) -&gt; \"Tree\":\n    \"\"\"\n    Build the Barnes-Hut tree structure.\n\n    Returns\n    -------\n    self : Tree\n        Returns self for method chaining\n    \"\"\"\n    self._tree = build_tree(\n        self.positions, self.masses, \n        leaf_size=self.leaf_size, backend=self.backend, dim=self.dim\n    )\n    self._is_built = True\n    return self\n</code></pre>"},{"location":"api/#bhut.Tree.evaluate_accelerations","title":"evaluate_accelerations","text":"<pre><code>evaluate_accelerations(softening, theta=0.5, G=1.0)\n</code></pre> <p>Evaluate gravitational accelerations for all particles in the tree.</p> <p>Parameters:</p> Name Type Description Default <code>softening</code> <code>float or array_like</code> <p>Gravitational softening length(s). If scalar, same softening is used for all particles. If array, must have shape (N,) for per-particle softening.</p> required <code>theta</code> <code>float</code> <p>Opening angle criterion for Barnes-Hut approximation. Smaller values give higher accuracy but slower computation. Typical range: 0.1-1.0.</p> <code>0.5</code> <code>G</code> <code>float</code> <p>Gravitational constant</p> <code>1.0</code> <p>Returns:</p> Name Type Description <code>accelerations</code> <code>(array_like, shape(N, D))</code> <p>Gravitational accelerations for each particle</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If tree has not been built (call <code>build()</code> first)</p> <code>ValueError</code> <p>If input parameters have invalid shapes or values</p> Source code in <code>bhut/api.py</code> <pre><code>def evaluate_accelerations(\n    self, \n    softening: Union[float, NDArray[np.floating[Any]]], \n    theta: float = 0.5,\n    G: float = 1.0\n) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"\n    Evaluate gravitational accelerations for all particles in the tree.\n\n    Parameters\n    ----------\n    softening : float or array_like\n        Gravitational softening length(s). If scalar, same softening is used\n        for all particles. If array, must have shape (N,) for per-particle\n        softening.\n    theta : float, default 0.5\n        Opening angle criterion for Barnes-Hut approximation. Smaller values\n        give higher accuracy but slower computation. Typical range: 0.1-1.0.\n    G : float, default 1.0\n        Gravitational constant\n\n    Returns\n    -------\n    accelerations : array_like, shape (N, D)\n        Gravitational accelerations for each particle\n\n    Raises\n    ------\n    RuntimeError\n        If tree has not been built (call `build()` first)\n    ValueError\n        If input parameters have invalid shapes or values\n    \"\"\"\n    if self._tree is None:\n        raise RuntimeError(\"Tree not built. Call build() first.\")\n\n    # Validate inputs\n    if not isinstance(softening, (int, float)):\n        raise ValueError(\"Only scalar softening is currently supported\")\n\n    if softening &lt; 0:\n        raise ValueError(\"Softening must be non-negative\")\n\n    if theta &lt; 0:\n        raise ValueError(\"Opening angle theta must be non-negative\")\n\n    # Use the standalone function to compute accelerations\n    accelerations_np = evaluate_accelerations(\n        self._tree, self.positions, self.masses, theta, softening, G\n    )\n\n    # Convert back to original array type  \n    xp = get_namespace(self.positions, self.backend)\n    return xp.asarray(accelerations_np)\n</code></pre>"},{"location":"api/#bhut.Tree.rebuild","title":"rebuild","text":"<pre><code>rebuild(new_positions, new_masses=None)\n</code></pre> <p>Rebuild the tree with new positions and optionally new masses.</p> <p>Parameters:</p> Name Type Description Default <code>new_positions</code> <code>array_like</code> <p>New particle positions, shape (N, dim)</p> required <code>new_masses</code> <code>array_like</code> <p>New particle masses, shape (N,). If None, keeps existing masses.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>Tree</code> <p>Returns self for method chaining</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If new arrays have incompatible shapes</p> Source code in <code>bhut/api.py</code> <pre><code>def rebuild(\n    self, new_positions: ArrayLike, new_masses: Optional[ArrayLike] = None\n) -&gt; \"Tree\":\n    \"\"\"\n    Rebuild the tree with new positions and optionally new masses.\n\n    Parameters\n    ----------\n    new_positions : array_like\n        New particle positions, shape (N, dim)\n    new_masses : array_like, optional\n        New particle masses, shape (N,). If None, keeps existing masses.\n\n    Returns\n    -------\n    self : Tree\n        Returns self for method chaining\n\n    Raises\n    ------\n    ValueError\n        If new arrays have incompatible shapes\n    \"\"\"\n    # Use existing masses if not provided\n    if new_masses is None:\n        new_masses = self.masses\n\n    # Validate new inputs\n    new_positions, new_masses, _ = _validate_accelerations_inputs(\n        new_positions, new_masses,\n        dim=self.dim, softening=0.0, theta=0.5, G=1.0, leaf_size=self.leaf_size\n    )\n\n    # Update stored arrays\n    self.positions = new_positions\n    self.masses = new_masses\n\n    # Mark as needing rebuild\n    self._is_built = False\n    self._tree = None\n\n    # Rebuild tree\n    return self.build()\n</code></pre>"},{"location":"api/#bhut.Tree.refit","title":"refit","text":"<pre><code>refit(new_positions, new_masses=None)\n</code></pre> <p>Refit the tree with new positions, keeping the same topology.</p> <p>This is faster than rebuilding when particles move slightly. Uses efficient O(M) algorithm where M is number of tree nodes.</p> <p>Parameters:</p> Name Type Description Default <code>new_positions</code> <code>array_like</code> <p>New particle positions, shape (N, dim)</p> required <code>new_masses</code> <code>array_like</code> <p>New particle masses, shape (N,). If None, keeps existing masses.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>Tree</code> <p>Returns self for method chaining</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If arrays have incompatible shapes or tree is not built</p> Source code in <code>bhut/api.py</code> <pre><code>def refit(self, new_positions: ArrayLike, new_masses: Optional[ArrayLike] = None) -&gt; \"Tree\":\n    \"\"\"\n    Refit the tree with new positions, keeping the same topology.\n\n    This is faster than rebuilding when particles move slightly.\n    Uses efficient O(M) algorithm where M is number of tree nodes.\n\n    Parameters\n    ----------\n    new_positions : array_like\n        New particle positions, shape (N, dim)\n    new_masses : array_like, optional\n        New particle masses, shape (N,). If None, keeps existing masses.\n\n    Returns\n    -------\n    self : Tree\n        Returns self for method chaining\n\n    Raises\n    ------\n    ValueError\n        If arrays have incompatible shapes or tree is not built\n    \"\"\"\n    if not self._is_built or self._tree is None:\n        raise ValueError(\"Tree must be built before refitting. Call build() first.\")\n\n    # Use existing masses if not provided\n    if new_masses is None:\n        new_masses = self.masses\n\n    # Validate inputs\n    new_positions, new_masses, _ = _validate_accelerations_inputs(\n        new_positions, new_masses,\n        dim=self.dim, softening=0.0, theta=0.5, G=1.0, leaf_size=self.leaf_size\n    )\n\n    # Check if refit is recommended vs rebuild\n    if not should_refit_vs_rebuild(self._tree, new_positions):\n        # Fall back to rebuild for major changes\n        return self.rebuild(new_positions, new_masses)\n\n    # Perform efficient refit\n    self._tree = refit_tree(self._tree, new_positions, new_masses, self._xp)\n\n    # Update stored arrays\n    self.positions = new_positions\n    self.masses = new_masses\n\n    return self\n</code></pre>"},{"location":"api/#bhut.accelerations","title":"accelerations","text":"<pre><code>accelerations(positions, masses, *, theta=0.5, softening=0.0, G=1.0, dim=3, backend='auto', leaf_size=32, criterion='bh', multipole='mono')\n</code></pre> <p>Compute gravitational accelerations using the Barnes-Hut algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>positions</code> <code>array_like</code> <p>Particle positions, shape (N, dim)</p> required <code>masses</code> <code>array_like</code> <p>Particle masses, shape (N,)</p> required <code>theta</code> <code>float</code> <p>Opening angle criterion. 0.0 gives direct sum, larger values are more approximate. Default: 0.5</p> <code>0.5</code> <code>softening</code> <code>float or array_like</code> <p>Plummer softening length to avoid singularities. Can be scalar or array of shape (N,). Default: 0.0</p> <code>0.0</code> <code>G</code> <code>float</code> <p>Gravitational constant. Default: 1.0</p> <code>1.0</code> <code>dim</code> <code>int</code> <p>Spatial dimensions (2 or 3). Default: 3</p> <code>3</code> <code>backend</code> <code>str</code> <p>Array backend (\"numpy\", \"dask\", or \"auto\"). Default: \"auto\"</p> <code>'auto'</code> <code>leaf_size</code> <code>int</code> <p>Maximum particles per leaf node. Default: 32</p> <code>32</code> <code>criterion</code> <code>str</code> <p>Tree opening criterion (\"bh\" for Barnes-Hut). Default: \"bh\"</p> <code>'bh'</code> <code>multipole</code> <code>str</code> <p>Multipole expansion order (\"mono\" for monopole). Default: \"mono\"</p> <code>'mono'</code> <p>Returns:</p> Name Type Description <code>accelerations</code> <code>ndarray</code> <p>Gravitational accelerations, shape (N, dim)</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If input shapes are incompatible or parameters are invalid</p> Source code in <code>bhut/api.py</code> <pre><code>def accelerations(\n    positions: ArrayLike,\n    masses: ArrayLike,\n    *,\n    theta: float = 0.5,\n    softening: Union[float, ArrayLike] = 0.0,\n    G: float = 1.0,\n    dim: int = 3,\n    backend: str = \"auto\",\n    leaf_size: int = 32,\n    criterion: str = \"bh\",\n    multipole: str = \"mono\",\n) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"\n    Compute gravitational accelerations using the Barnes-Hut algorithm.\n\n    Parameters\n    ----------\n    positions : array_like\n        Particle positions, shape (N, dim)\n    masses : array_like\n        Particle masses, shape (N,)\n    theta : float, optional\n        Opening angle criterion. 0.0 gives direct sum, larger values are more approximate.\n        Default: 0.5\n    softening : float or array_like, optional\n        Plummer softening length to avoid singularities. Can be scalar or array of shape (N,).\n        Default: 0.0\n    G : float, optional\n        Gravitational constant. Default: 1.0\n    dim : int, optional\n        Spatial dimensions (2 or 3). Default: 3\n    backend : str, optional\n        Array backend (\"numpy\", \"dask\", or \"auto\"). Default: \"auto\"\n    leaf_size : int, optional\n        Maximum particles per leaf node. Default: 32\n    criterion : str, optional\n        Tree opening criterion (\"bh\" for Barnes-Hut). Default: \"bh\"\n    multipole : str, optional\n        Multipole expansion order (\"mono\" for monopole). Default: \"mono\"\n\n    Returns\n    -------\n    accelerations : ndarray\n        Gravitational accelerations, shape (N, dim)\n\n    Raises\n    ------\n    ValueError\n        If input shapes are incompatible or parameters are invalid\n    \"\"\"\n    # Validate criterion and multipole parameters\n    if criterion != \"bh\":\n        raise ValueError(f\"criterion must be 'bh', got '{criterion}'\")\n    if multipole != \"mono\":\n        raise ValueError(f\"multipole must be 'mono', got '{multipole}'\")\n\n    # Get array namespace for backend\n    xp = get_namespace(positions, backend)\n\n    # Check if we're using Dask backend for special handling\n    is_dask = backend == \"dask\" or (backend == \"auto\" and _is_dask_array(positions))\n\n    if is_dask:\n        # For Dask arrays, do basic validation without converting to NumPy\n        # Validate dimensions parameter\n        _validate_dimensions(dim)\n\n        # Validate other parameters\n        if theta &lt; 0:\n            raise ValueError(f\"theta must be non-negative, got {theta}\")\n        if isinstance(softening, (int, float)) and softening &lt; 0:\n            raise ValueError(f\"softening must be non-negative, got {softening}\")\n        if leaf_size &lt;= 0:\n            raise ValueError(f\"leaf_size must be positive, got {leaf_size}\")\n\n        # Basic shape validation for Dask arrays\n        if len(positions.shape) != 2:\n            raise ValueError(f\"positions must be 2D array, got shape {positions.shape}\")\n        if len(masses.shape) != 1:\n            raise ValueError(f\"masses must be 1D array, got shape {masses.shape}\")\n\n        N, actual_dim = positions.shape\n        if actual_dim != dim:\n            raise ValueError(f\"positions has {actual_dim} dimensions but dim={dim}\")\n\n        if masses.shape[0] != N:\n            raise ValueError(f\"positions has {N} particles but masses has {masses.shape[0]} elements\")\n\n        # Skip numpy conversion and use specialized computation path\n        return _accelerations_dask(\n            positions, masses, theta=theta, softening=softening, G=G,\n            dim=dim, leaf_size=leaf_size, xp=xp\n        )\n    else:\n        # Standard computation path for NumPy arrays\n        # Validate and convert inputs\n        positions, masses, softening = _validate_accelerations_inputs(\n            positions, masses, \n            dim=dim, softening=softening, theta=theta, G=G, leaf_size=leaf_size\n        )\n\n        # Build tree structure \n        tree = build_tree(positions, masses, leaf_size=leaf_size, backend=backend, dim=dim)\n\n        # Evaluate accelerations\n        acc = evaluate_accelerations(\n            tree, positions, masses, theta=theta, softening=softening, G=G\n        )\n\n        return acc\n</code></pre>"},{"location":"dev/contributing/","title":"Contributing","text":"<p>We welcome contributions to bhut! This guide will help you set up a development environment and understand our development workflow.</p>"},{"location":"dev/contributing/#development-setup","title":"Development Setup","text":""},{"location":"dev/contributing/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code># Clone the repository\ngit clone https://github.com/username/bhut.git\ncd bhut\n\n# Create a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in development mode with all dependencies\npip install -e \".[dev,test,docs]\"\n</code></pre>"},{"location":"dev/contributing/#2-install-development-tools","title":"2. Install Development Tools","text":"<pre><code># Install pre-commit hooks for automatic formatting\npre-commit install\n</code></pre>"},{"location":"dev/contributing/#running-tests","title":"Running Tests","text":""},{"location":"dev/contributing/#full-test-suite","title":"Full Test Suite","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=bhut --cov-report=html\n</code></pre>"},{"location":"dev/contributing/#specific-test-categories","title":"Specific Test Categories","text":"<pre><code># Unit tests only\npytest tests/unit/\n\n# Integration tests\npytest tests/integration/\n\n# Performance tests\npytest tests/performance/\n\n# Edge cases\npytest tests/edge_cases/\n</code></pre>"},{"location":"dev/contributing/#code-quality","title":"Code Quality","text":""},{"location":"dev/contributing/#formatting-and-linting","title":"Formatting and Linting","text":"<p>We use ruff for both formatting and linting:</p> <pre><code># Format code\nruff format .\n\n# Check and fix linting issues\nruff check . --fix\n\n# Check without fixing\nruff check .\n</code></pre>"},{"location":"dev/contributing/#type-checking","title":"Type Checking","text":"<p>We use mypy for static type checking:</p> <pre><code># Run type checking\nmypy bhut/\n\n# Run with strict mode\nmypy --strict bhut/\n</code></pre>"},{"location":"dev/contributing/#documentation-preview","title":"Documentation Preview","text":"<p>To preview the documentation locally:</p> <pre><code>./scripts/preview_docs.sh\n</code></pre> <p>This script installs the required dependencies and starts a local server at http://localhost:8000. It is executable by default.</p>"},{"location":"dev/contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":""},{"location":"dev/contributing/#before-submitting","title":"Before Submitting","text":"<ol> <li>Test your changes: Ensure all tests pass</li> <li>Add tests: For new features or bug fixes</li> <li>Update docs: If you change the public API</li> <li>Check types: Run mypy without errors</li> <li>Format code: Run ruff format</li> </ol>"},{"location":"dev/contributing/#pr-checklist","title":"PR Checklist","text":"<ul> <li>[ ] Tests pass locally</li> <li>[ ] New code has tests</li> <li>[ ] Documentation updated if needed</li> <li>[ ] Type hints added for new code</li> <li>[ ] Descriptive commit messages</li> <li>[ ] No unnecessary dependencies added</li> </ul>"},{"location":"dev/contributing/#commit-message-format","title":"Commit Message Format","text":"<pre><code>type: short description\n\nLonger explanation if needed.\n\nFixes #123\n</code></pre> <p>Types: <code>feat</code>, <code>fix</code>, <code>docs</code>, <code>test</code>, <code>refactor</code>, <code>perf</code>, <code>chore</code></p>"},{"location":"dev/contributing/#development-tips","title":"Development Tips","text":"<ul> <li>Use descriptive variable names and add type hints</li> <li>Keep functions small and focused</li> <li>Add docstrings for public API</li> <li>Consider performance implications for hot paths</li> <li>Test edge cases (empty arrays, single particles, etc.)</li> </ul>"},{"location":"dev/contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Open an issue for bugs or feature requests</li> <li>Start discussions for design questions</li> <li>Check existing issues before creating new ones</li> </ul>"},{"location":"dev/design/","title":"Design Architecture","text":"<p>This document outlines the high-level architecture and design decisions of the bhut library.</p>"},{"location":"dev/design/#overview","title":"Overview","text":"<p>bhut is structured as a modular library with clear separation of concerns:</p> <pre><code>bhut/\n\u251c\u2500\u2500 api.py          # Public API functions\n\u251c\u2500\u2500 backends/       # Computational backends\n\u251c\u2500\u2500 tree/           # Tree data structures\n\u251c\u2500\u2500 traverse/       # Tree traversal algorithms\n\u251c\u2500\u2500 space/          # Spatial data structures\n\u2514\u2500\u2500 utils/          # Utilities and helpers\n</code></pre>"},{"location":"dev/design/#core-components","title":"Core Components","text":""},{"location":"dev/design/#1-backends-bhutbackends","title":"1. Backends (<code>bhut.backends</code>)","text":"<p>The backend system provides pluggable computational engines:</p> <ul> <li><code>numpy_</code>: Pure NumPy implementation for small to medium datasets</li> <li><code>dask_</code>: Distributed computing for large datasets</li> <li><code>base</code>: Abstract base class defining the backend interface</li> </ul> <pre><code># Backend selection\ntree = bhut.Tree(positions, masses, backend='numpy')\ntree = bhut.Tree(positions, masses, backend='dask')\n</code></pre>"},{"location":"dev/design/#2-tree-structure-bhuttree","title":"2. Tree Structure (<code>bhut.tree</code>)","text":"<p>Core tree data structures and operations:</p> <ul> <li><code>node.py</code>: Tree node implementation (internal and leaf nodes)</li> <li><code>build.py</code>: Tree construction algorithms</li> <li><code>refit.py</code>: Efficient tree updating for dynamic simulations</li> </ul>"},{"location":"dev/design/#3-traversal-bhuttraverse","title":"3. Traversal (<code>bhut.traverse</code>)","text":"<p>Tree traversal algorithms implementing the Barnes-Hut method:</p> <ul> <li><code>bh.py</code>: Main Barnes-Hut traversal algorithm</li> <li><code>kernels.py</code>: Force/potential calculation kernels</li> </ul>"},{"location":"dev/design/#4-spatial-structures-bhutspace","title":"4. Spatial Structures (<code>bhut.space</code>)","text":"<p>Spatial data structures and utilities:</p> <ul> <li><code>bbox.py</code>: Bounding box operations for tree subdivision</li> </ul>"},{"location":"dev/design/#5-utilities-bhututils","title":"5. Utilities (<code>bhut.utils</code>)","text":"<p>Helper functions and optimizations:</p> <ul> <li><code>morton.py</code>: Morton encoding for spatial ordering</li> </ul>"},{"location":"dev/design/#algorithm-flow","title":"Algorithm Flow","text":"<pre><code>flowchart TD\n    A[Input: positions, masses] --&gt; B[Tree Construction]\n    B --&gt; C[Recursive Subdivision]\n    C --&gt; D[Compute Node Properties]\n    D --&gt; E[Barnes-Hut Traversal]\n    E --&gt; F[Force/Potential Calculation]\n    F --&gt; G[Output: forces/potentials]</code></pre> <p>Note: Mermaid diagram will be rendered in the documentation</p>"},{"location":"dev/design/#design-principles","title":"Design Principles","text":""},{"location":"dev/design/#1-modularity","title":"1. Modularity","text":"<p>Each component has a single responsibility and clear interfaces.</p>"},{"location":"dev/design/#2-performance","title":"2. Performance","text":"<ul> <li>Efficient tree construction using Morton ordering</li> <li>Vectorized operations where possible</li> <li>Memory-conscious data structures</li> </ul>"},{"location":"dev/design/#3-flexibility","title":"3. Flexibility","text":"<ul> <li>Multiple backends for different scales</li> <li>Configurable parameters (theta, leaf_size, etc.)</li> <li>Support for both 2D and 3D problems</li> </ul>"},{"location":"dev/design/#4-extensibility","title":"4. Extensibility","text":"<ul> <li>Plugin architecture for backends</li> <li>Abstract base classes for easy extension</li> <li>Clear separation of algorithm from implementation</li> </ul>"},{"location":"dev/design/#memory-layout","title":"Memory Layout","text":"<p>The tree uses a compact memory layout for cache efficiency:</p> <ul> <li>Nodes stored in breadth-first order</li> <li>Contiguous arrays for node properties</li> <li>Minimal indirection in hot paths</li> </ul>"},{"location":"dev/design/#threading-and-parallelization","title":"Threading and Parallelization","text":"<ul> <li>NumPy backend: Uses NumPy's built-in parallelization</li> <li>Dask backend: Distributed computation across workers</li> <li>Thread-safe by design for read-only operations</li> </ul>"},{"location":"dev/design/#future-extensions","title":"Future Extensions","text":"<p>Planned architectural improvements:</p> <ul> <li>GPU backend using CuPy/JAX</li> <li>Adaptive mesh refinement</li> <li>Multipole expansions for higher accuracy</li> </ul>"},{"location":"theory/barnes-hut/","title":"Barnes-Hut Algorithm","text":"<p>The Barnes-Hut algorithm is a fast approximate method for computing N-body forces, reducing the computational complexity from O(N\u00b2) to O(N log N).</p>"},{"location":"theory/barnes-hut/#basic-principle","title":"Basic Principle","text":"<p>Instead of computing forces between every pair of particles, the Barnes-Hut algorithm groups distant particles and treats them as a single mass located at their center of mass.</p>"},{"location":"theory/barnes-hut/#tree-construction","title":"Tree Construction","text":"<p>The algorithm builds a spatial tree (quadtree in 2D, octree in 3D) by recursively subdividing space:</p> <ol> <li>Start with a bounding box containing all particles</li> <li>If a region contains more than one particle, subdivide it</li> <li>Continue until each leaf contains at most one particle</li> </ol>"},{"location":"theory/barnes-hut/#force-calculation","title":"Force Calculation","text":"<p>For each particle, traverse the tree and decide whether to:</p> <ul> <li>Use the node: If the node is sufficiently far away (determined by the \u03b8 parameter)</li> <li>Recurse: If the node is too close, examine its children</li> </ul>"},{"location":"theory/barnes-hut/#the-criterion","title":"The \u03b8 Criterion","text":"<p>A node is considered \"far enough\" if:</p> \\[\\frac{s}{d} &lt; \\theta\\] <p>Where: - \\(s\\) = size of the node (width/height of bounding box) - \\(d\\) = distance from particle to node's center of mass - \\(\\theta\\) = accuracy parameter (0 = exact, larger = more approximate)</p>"},{"location":"theory/barnes-hut/#force-equations","title":"Force Equations","text":""},{"location":"theory/barnes-hut/#gravitational-force","title":"Gravitational Force","text":"<p>The gravitational force between two particles is:</p> \\[\\vec{F}_{ij} = -G \\frac{m_i m_j}{|\\vec{r}_{ij}|^3} \\vec{r}_{ij}\\] <p>Where: - \\(G\\) = gravitational constant - \\(m_i, m_j\\) = masses of particles \\(i\\) and \\(j\\) - \\(\\vec{r}_{ij} = \\vec{r}_j - \\vec{r}_i\\) = displacement vector</p>"},{"location":"theory/barnes-hut/#potential-energy","title":"Potential Energy","text":"<p>The gravitational potential at position \\(\\vec{r}_i\\) due to particle \\(j\\) is:</p> \\[\\phi_i = -G \\frac{m_j}{|\\vec{r}_{ij}|}\\]"},{"location":"theory/barnes-hut/#softened-force","title":"Softened Force","text":"<p>To avoid singularities at small distances, a softening parameter \\(\\epsilon\\) is often used:</p> \\[\\vec{F}_{ij} = -G \\frac{m_i m_j}{(|\\vec{r}_{ij}|^2 + \\epsilon^2)^{3/2}} \\vec{r}_{ij}\\]"},{"location":"theory/barnes-hut/#plummer-softening","title":"Plummer Softening","text":"<p>We use Plummer softening: [ \\Phi_i = -G \\sum_{j \\ne i} \\frac{m_j}{\\sqrt{|\\mathbf{r}_i-\\mathbf{r}_j|^2 + \\varepsilon^2}}, \\qquad \\mathbf{a}_i = -\\nabla \\Phi_i ]</p>"},{"location":"theory/barnes-hut/#quadtreeoctree-split-mermaid","title":"Quadtree/Octree Split (Mermaid)","text":"<pre><code>graph TD\n  R[Root Cell]\n  R --&gt; C1[Child 1]\n  R --&gt; C2[Child 2]\n  R --&gt; C3[Child 3]\n  R --&gt; C4[Child 4]</code></pre>"},{"location":"theory/barnes-hut/#center-of-mass-calculation","title":"Center of Mass Calculation","text":"<p>For each tree node, the center of mass and total mass are computed:</p> \\[\\vec{R}_{cm} = \\frac{\\sum_i m_i \\vec{r}_i}{\\sum_i m_i}\\] \\[M_{total} = \\sum_i m_i\\]"},{"location":"theory/barnes-hut/#multipole-expansion","title":"Multipole Expansion","text":"<p>The Barnes-Hut algorithm can be viewed as a first-order multipole expansion. Higher-order terms can be included for improved accuracy:</p> \\[\\phi(\\vec{r}) = -G \\sum_{l=0}^{\\infty} \\sum_{m=-l}^{l} \\frac{A_{lm}}{r^{l+1}} Y_l^m(\\theta, \\phi)\\] <p>Where \\(A_{lm}\\) are the multipole moments and \\(Y_l^m\\) are spherical harmonics.</p>"},{"location":"theory/barnes-hut/#algorithm-complexity","title":"Algorithm Complexity","text":"<ul> <li>Tree construction: O(N log N)</li> <li>Force evaluation: O(N log N) for N particles</li> <li>Memory usage: O(N)</li> </ul> <p>The key insight is that the number of nodes at each level of the tree is bounded, leading to the logarithmic factor.</p>"},{"location":"theory/complexity/","title":"Computational Complexity","text":"<p>This page analyzes the computational complexity of the Barnes-Hut algorithm and discusses the accuracy-performance tradeoffs.</p>"},{"location":"theory/complexity/#time-complexity","title":"Time Complexity","text":""},{"location":"theory/complexity/#tree-construction-on-log-n","title":"Tree Construction: O(N log N)","text":"<p>Building the spatial tree requires:</p> <ol> <li>Sorting particles: O(N log N) using Morton ordering</li> <li>Tree assembly: O(N) to build the tree structure</li> <li>Computing node properties: O(N) to calculate centers of mass</li> </ol> <p>The dominating factor is the sorting step, giving overall O(N log N) complexity.</p>"},{"location":"theory/complexity/#force-evaluation-om-log-n","title":"Force Evaluation: O(M log N)","text":"<p>For M target particles querying forces from N source particles:</p> <ul> <li>Tree traversal: Each particle visits O(log N) nodes on average</li> <li>Force calculation: O(1) per node interaction</li> <li>Total: O(M log N)</li> </ul> <p>When M = N (self-force calculation), this becomes O(N log N).</p>"},{"location":"theory/complexity/#comparison-with-direct-methods","title":"Comparison with Direct Methods","text":"Method Time Complexity Accuracy Direct (brute force) O(N\u00b2) Exact Barnes-Hut O(N log N) Approximate Fast Multipole Method O(N) Approximate"},{"location":"theory/complexity/#space-complexity","title":"Space Complexity","text":""},{"location":"theory/complexity/#memory-usage-on","title":"Memory Usage: O(N)","text":"<ul> <li>Particle storage: 3N floats for positions (2N in 2D)</li> <li>Tree nodes: ~4N/3 nodes in worst case (complete tree)</li> <li>Node properties: Center of mass, total mass per node</li> <li>Total: O(N) memory usage</li> </ul>"},{"location":"theory/complexity/#cache-efficiency","title":"Cache Efficiency","text":"<p>The tree structure is optimized for cache performance:</p> <ul> <li>Breadth-first node ordering improves locality</li> <li>Contiguous arrays reduce memory fragmentation</li> <li>Vectorized operations maximize throughput</li> </ul>"},{"location":"theory/complexity/#accuracy-vs-performance","title":"Accuracy vs Performance","text":""},{"location":"theory/complexity/#the-parameter","title":"The \u03b8 Parameter","text":"<p>The accuracy-speed tradeoff is controlled by the \u03b8 (theta) parameter:</p> \\[\\text{Error} \\propto \\theta^2\\] \\[\\text{Speed} \\propto \\frac{1}{\\log(1/\\theta)}\\] \u03b8 Value Relative Error Relative Speed Use Case 0.0 0% (exact) 1\u00d7 (slowest) Validation 0.1 ~1% 2-3\u00d7 High accuracy 0.5 ~25% 5-10\u00d7 Balanced (recommended) 1.0 ~100% 10-20\u00d7 Fast approximation 2.0 ~400% 20-50\u00d7 Very rough estimate"},{"location":"theory/complexity/#error-analysis","title":"Error Analysis","text":"<p>The error in Barnes-Hut comes from two sources:</p> <ol> <li>Approximation error: Treating distant groups as point masses</li> <li>Truncation error: Using first-order multipole expansion</li> </ol> <p>The total relative error is approximately:</p> \\[\\epsilon_{rel} \\approx \\theta^2 \\left(1 + \\frac{s}{2d}\\right)\\] <p>Where s/d is the size-to-distance ratio of the farthest node used in approximation.</p>"},{"location":"theory/complexity/#adaptive-accuracy","title":"Adaptive Accuracy","text":"<p>For applications requiring variable accuracy:</p> <pre><code># High accuracy for nearby interactions\nforces_precise = bhut.force(positions, masses, theta=0.1)\n\n# Lower accuracy for distant background\nforces_approx = bhut.force(positions, masses, theta=1.0)\n</code></pre>"},{"location":"theory/complexity/#scaling-analysis","title":"Scaling Analysis","text":""},{"location":"theory/complexity/#strong-scaling-fixed-problem-size","title":"Strong Scaling (Fixed Problem Size)","text":"<p>Performance with increasing number of processors:</p> <ul> <li>Ideal speedup: Limited by O(log N) tree traversal</li> <li>Communication overhead: Increases with processor count</li> <li>Memory bandwidth: Can become bottleneck</li> </ul>"},{"location":"theory/complexity/#weak-scaling-fixed-work-per-processor","title":"Weak Scaling (Fixed Work per Processor)","text":"<p>Performance with proportionally increasing problem size:</p> <ul> <li>Tree depth: Grows as log N, maintaining efficiency</li> <li>Load balancing: Space-filling curves help distribute work</li> <li>Network communication: Scales well for distributed systems</li> </ul>"},{"location":"theory/complexity/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"theory/complexity/#algorithmic-optimizations","title":"Algorithmic Optimizations","text":"<ol> <li>Morton ordering: Improves cache locality and tree balance</li> <li>Vectorization: Process multiple particles simultaneously</li> <li>Tree reuse: Rebuild only when necessary for dynamic systems</li> </ol>"},{"location":"theory/complexity/#implementation-optimizations","title":"Implementation Optimizations","text":"<ol> <li>Memory pooling: Reduce allocation overhead</li> <li>SIMD instructions: Vectorize force calculations</li> <li>Prefetching: Hide memory latency</li> </ol>"},{"location":"theory/complexity/#parallel-optimizations","title":"Parallel Optimizations","text":"<ol> <li>Shared-memory: OpenMP for multi-core parallelization</li> <li>Distributed-memory: MPI for cluster computing</li> <li>GPU acceleration: CUDA/OpenCL for massively parallel systems</li> </ol>"},{"location":"theory/complexity/#performance-benchmarks","title":"Performance Benchmarks","text":"<p>Typical performance on modern hardware:</p> N Particles Direct O(N\u00b2) Barnes-Hut O(N log N) Speedup 1,000 1ms 0.1ms 10\u00d7 10,000 100ms 2ms 50\u00d7 100,000 10s 30ms 333\u00d7 1,000,000 16min 400ms 2,400\u00d7 <p>Benchmarks assume \u03b8 = 0.5 on a modern CPU</p>"}]}